# Q&A Application using RAG on AWS â˜ï¸ğŸ§ 

## Overview
This project implements a **Retrieval-Augmented Generation (RAG)** powered Question-Answering system, deployed on **AWS cloud infrastructure**.  
It enables users to upload documents and ask natural language questions, with answers generated by combining document retrieval and large language models.

Built with:
- **AWS S3** for document storage
- **AWS Lambda** for serverless compute
- **AWS API Gateway** for exposing endpoints
- **AWS DynamoDB** for metadata storage
- **AWS Bedrock / SageMaker** for LLM integration
- **FAISS / AWS OpenSearch** for vector search
- **Streamlit** for the user interface

---

## Features
- ğŸ“‚ Upload documents to AWS S3  
- ğŸ” Retrieve relevant chunks using FAISS or OpenSearch embeddings  
- ğŸ¤– Generate contextual answers with LLMs hosted on AWS (Bedrock/SageMaker)  
- âš¡ Serverless architecture with AWS Lambda and API Gateway  
- ğŸ¨ Interactive Streamlit UI  

---
## ğŸ“š Resources

- [Building and Evaluating Q&A Application using Amazon Bedrock Knowledge Bases with RAG Assessment (RAGAS Framework)](https://builder.aws.com/content/36TVYZFlUUDzeqVglivCxsvOnRh/building-and-evaluating-qanda-application-using-amazon-bedrock-knowledge-bases-using-rag-assessment-ragas-framework)
---
## Architecture Diagram
```text
User â†’ Streamlit UI â†’ API Gateway â†’ Lambda â†’ DynamoDB / S3 â†’ Vector DB (FAISS/OpenSearch) â†’ LLM (Bedrock/SageMaker)
